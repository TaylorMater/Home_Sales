UTA Data Analytics Bootcamp

Module 22 - Spark and Parquet/Big Data




## Description

This contains my submission for module 22 of the UTA Data Analytics Bootcamp. We were tasked with completing a supplied jupyter notebook that would test using pyspark.  

NOTE:

Hadoop/parquet did not work. I tried playing with environment variables and installs, but it seemed like the bug happened for almost everyone in the class, and no solution was given to us. As such, I skipped over the parquet section of the homework, and I am submitting what I have. 


## Requirements

To be able to run the jupyter notebooks, you will need the following libraries:

-   hadoop/spark installation (3/3.5.1)
-   findspark   

The project was run using Python 3.10.13. 


